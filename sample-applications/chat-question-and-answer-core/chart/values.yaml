image:
  registry: "intel/"
  backendTag: "core_1.2.1"
  backendGpuTag: "core_gpu_1.2.1"
  pullPolicy: IfNotPresent

global:
  http_proxy:
  https_proxy:
  no_proxy:
  huggingface:
    apiToken:
  model_cache_path: "/tmp/model_cache"
  UI_NODEPORT:
  pvc:
    size: 60Gi
  keeppvc: false # true  to persist models across multiple deployments
chatqna:
  name: chatqna-core
  service:
    type: ClusterIP
    port: 8888
  readinessProbe:
    httpGet:
      path: /v1/chatqna/health
      port: 8888
    initialDelaySeconds: 30
    periodSeconds: 30

gpu:
  enabled: false
  devices: /dev/dri
  group_add: $(stat -c "%g" /dev/dri/render*)
  key:  #update as per the cluster node label key for GPU assigned by device Plugin

uiService:
  name: chatqna-core-ui
  type: ClusterIP
  port: 8102
